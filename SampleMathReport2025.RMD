---
title: "Title"
output:
  word_document:
    reference_docx: word-styles-reference-01.docx
    toc: no
  pdf_document:
    toc: no
  html_document:
    toc: no
---

```{r setup, include=FALSE}
## set standard code chunk options
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, error=FALSE, include=FALSE, message=FALSE, comment=NA)

## load libraries
library(dplyr)
library(cowplot)
library(flextable)
library(forcats)
library(ggplot2)
library(ggpubr)
library(ggtext)
library(grid)
library(gridExtra)
library(HH)
library(officer)
library(officedown)
library(psych)
library(RColorBrewer)
library(RCurl)
library(reshape2)
library(robustbase)
library(SnowballC)
library(stringi)
library(stringr)
library(textcat)
library(tidyr)
library(tm)
library(viridis)
library(wordcloud)
library(XML)

## turn off dpyr warning message for summarise with grouping
options(dplyr.summarise.inform = FALSE)

## Set color brewer palate to use in plots
pvmpalette <- "PRGn"
pvmboxplotpalette <- "Greens"
pvmpalette2 <- "PuBuGn"
upperselectorcolor <- "#7FBF7B"
lowerselectorcolor <- "#AF8DC3"
meanupperselector <- .5
meanlowerselector <- -.5

## Set significant digits
sigdig <- 0
sigdig1 <- 1
sigdig2 <- 2
sigdig3 <- 3
sigdig4 <- 4

## set subgrouplimit that determines minimum number of individuals required to display a subgroup
subgrouplimit = 10

fp <- fp_par(text.align = "center", padding.top = 120)
ft <- fp_text(font.size = 14, bold = TRUE, color = "#000000")

## Trim and decimal functions
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
specify_decimal <- function(x, k) trimws(format(round(x, k), nsmall=k))
```

```{r load data files}
## set working directory
setwd('//nas01.itap.purdue.edu//edu_create//ADMIN//ELRC//Data Team SHARED//Data Report Templates//SampleMath//')

## read data
SampleMathPRE <- read.csv('//nas01.itap.purdue.edu//edu_create//ADMIN//ELRC//Data Team//Data Files//SampleMath//SampleMathPre.csv')

SampleMathPOST <- read.csv('//nas01.itap.purdue.edu//edu_create//ADMIN//ELRC//Data Team//Data Files//SampleMath//SampleMathPost.csv')

SampleMathMergeDF <- merge(SampleMathPRE, SampleMathPOST, by.x="PRE_STUDENTID", by.y="POST_STUDENTID", all=TRUE)

```

```{r check for measure normality function}
check_measure_normality <- function(df, measure_items) {
	## Sample function call
	## is_normal <- check_measure_normality(vetupcollege, PRE_CA_VM_LIST)
	## Sample usage
	## Use the result to decide whether to use mean or median
	## if (is_normal) {
	## 	cat("Use MEAN for summary statistics.\n")
	## } else {
	## cat("Use MEDIAN for summary statistics.\n")
	## }

  ## Initialize a vector to store normality results
  normality_results <- data.frame(
    Item = measure_items,
    P_Value = NA,
    Is_Normal = NA
  )
  
  ## Loop through each item and run Shapiro-Wilk test
  for (i in seq_along(measure_items)) {
    item <- measure_items[i]
    values <- df[[item]]
	
    ## Remove NA values before testing
    values <- na.omit(values)
    
    ## Run Shapiro-Wilk test if there are enough values
    if (length(values) >= 3) {
      test <- shapiro.test(values)
      normality_results$P_Value[i] <- test$p.value
      normality_results$Is_Normal[i] <- test$p.value > 0.05
    } else {
      normality_results$P_Value[i] <- NA
      normality_results$Is_Normal[i] <- NA
    }
  }
  
  ## Count how many items are normal
  num_normal <- sum(normality_results$Is_Normal, na.rm = TRUE)
  num_total <- sum(!is.na(normality_results$Is_Normal))
  
  ## Determine majority
  majority_normal <- num_normal > (num_total / 2)
  
  ## Print summary table
  ## print(normality_results)
  ## cat("\nMajority of items normal:", majority_normal, "\n")
  
  return(majority_normal)
}
```

```{r single point in time measure table}
build_table_function <- function(df, measure_item_list, measure_values, measure_avg, include_measure, measure_normality, sectionTitle, sig_digits) {
  
  ## build_table_function(vetupcollege, awareness_item_list, PRE_CA_VM_LIST, 'PRE_CA_VM_Avg', awareness_include_measure, awareness_normality, 'Overall Scale Score', sigdig2)
  
  ## Set default number of significant digits
  sigdig1 <- 1        ## for range
  sigdig2 <- 2        ## For mean, median, and SD
  sigdig4 <- 4        ## For p-values
    
  ## Determine whether to use mean or median and set label
  value_label <- if (measure_normality) "Mean" else "Median"
  
  ## Create an empty data frame to store table content
  table_df <- data.frame(
    Item = measure_item_list,
    Value = NA,
    SD_or_Range = NA
  )
  
  ## Loop through each item to calculate mean/median and SD or Range
  for (i in seq_along(measure_values)) {
    varname <- measure_values[i]
    values <- df[[varname]]
    values <- na.omit(values)
    
    ## Calculate mean/median and SD or Range
    if (measure_normality) {
      table_df$Value[i] <- signif(mean(values), sig_digits)
      table_df$SD_or_Range[i] <- signif(sd(values), sig_digits)
    } else {
      table_df$Value[i] <- signif(median(values), sig_digits)
      range_vals <- range(values)
      table_df$SD_or_Range[i] <- paste0(signif(range_vals[1], 1), " - ", signif(range_vals[2], 1))
    }
  }
  
  ## Optionally add the overall measure average at the top
  if (include_measure == 'Yes') {
    avg_values <- df[[measure_avg]]
    avg_values <- na.omit(avg_values)
    
    avg_row <- data.frame(
      Item = sectionTitle,
      Value = if (measure_normality) signif(mean(avg_values), sig_digits) else signif(median(avg_values), sig_digits),
      SD_or_Range = if (measure_normality) {
        signif(sd(avg_values), sig_digits)
      } else {
        range_vals <- range(avg_values)
        paste0(signif(range_vals[1], 1), " - ", signif(range_vals[2], 1))
      }
    )
    
    ## Add the average row to the top of the table
    table_df <- rbind(avg_row, table_df)
  }
  
  ## Create flextable
  library(flextable)
  ft <- flextable(table_df)
  
  ## set format for flextable
  ## Rename column headers
  ft <- set_header_labels(ft, Value = value_label, SD_or_Range = if (measure_normality) "SD" else "Range")
  
  ## Bold the first row if the average is included
  if (include_measure == 'Yes') {
    ft <- bold(ft, i = 1, bold = TRUE)
  }
  ## Bold all column headers
  ft <- bold(ft, part = "header")
  
  ## Right-align numeric columns
  ft <- align(ft, j = c("Value", "SD_or_Range"), align = "right", part = "all")
  
  ## Set flextable width
  ft <- autofit(ft)
  ft <- height(ft, height=.1)
  ft <- width(ft, j=1, 5.5)
  ft <- width(ft, j=2, 0.7)
  ft <- width(ft, j=3, 1)
  
  ## Shade every other row starting from the second
  row_indices <- seq(2, nrow(table_df), by = 2)
  ft <- bg(ft, i = row_indices, bg = "#EFEFEF")
  
  ## align cells at top
  ft <- valign(ft, i=NULL, j=NULL, part="all", valign="top")
  ft <- padding(ft, i=NULL, padding.top=.7, padding.bottom=.7)
  
  ## Return the flextable
  return(ft)
}
```

```{r comparison measure table}
build_comparison_table_function <- function(df, item_list, pre_values, post_values, pre_avg, post_avg, include_measure, pre_normality, post_normality, sectionTitle) {

  ## build_comparison_table_function(vetupcollege, awareness_item_list, PRE_CA_VM_LIST, POST_CA_VM_LIST, 'PRE_CA_VM_Avg', 'POST_CA_VM_Avg', awareness_include_measure, awareness_normality, awareness_normality, 'Overall Scale Score')  
  
  ## Set default number of significant digits
  sigdig1 <- 1        ## for range
  sigdig2 <- 2        ## For mean, median, and SD
  sigdig4 <- 4        ## For p-values
  upperselectorcolor <- "#7FBF7B"
  lowerselectorcolor <- "#A6D8A8"
  
  ## Determine whether to use mean or median
  ## Only use means if both pre and post items are both 
  ## distributed normally
  use_mean <- pre_normality && post_normality
  
  ## Set column labels
  value_label <- if (use_mean) "Mean" else "Median"
  sd_range_label <- if (use_mean) "SD" else "Range"
  
  ## Create empty data frame
  table_df <- data.frame(
    Item = item_list,
    Pre_Value = NA,
    Pre_SD_or_Range = NA,
    Post_Value = NA,
    Post_SD_or_Range = NA,
    P_Value = NA
  )
  
  ## Loop through each item to calculate mean/median and SD or Range
  for (i in seq_along(item_list)) {
    pre_var <- pre_values[i]
    post_var <- post_values[i]
    
    pre_data <- na.omit(df[[pre_var]])
    post_data <- na.omit(df[[post_var]])
    
    ## Compute values for mean and sd or median and range
    if (use_mean) {
      table_df$Pre_Value[i] <- signif(mean(pre_data), sigdig2)
      table_df$Pre_SD_or_Range[i] <- signif(sd(pre_data), sigdig2)
      table_df$Post_Value[i] <- signif(mean(post_data), sigdig2)
      table_df$Post_SD_or_Range[i] <- signif(sd(post_data), sigdig2)
    } else {
      table_df$Pre_Value[i] <- signif(median(pre_data), sigdig2)
      table_df$Pre_SD_or_Range[i] <- paste0(signif(min(pre_data), 1), " - ", signif(max(pre_data), 1))
      table_df$Post_Value[i] <- signif(median(post_data), sigdig2)
      table_df$Post_SD_or_Range[i] <- paste0(signif(min(post_data), 1), " - ", signif(max(post_data), 1))
    }
    
    ## Compute p-values based on normality
	## if both pre and post are normally distributed 
	## calculate p-value based on t-test otherwise
	## calculate p-values based on wilcoxon signed rank test 
    if (pre_normality && post_normality) {
      test <- t.test(pre_data, post_data, paired = TRUE)
    } else {
      test <- wilcox.test(pre_data, post_data, paired = TRUE)
    }
    
    table_df$P_Value[i] <- round(test$p.value, sigdig4)
  }
  
  ## Optionally add overall average row
  if (include_measure == 'Yes') {
    pre_avg_data <- na.omit(df[[pre_avg]])
    post_avg_data <- na.omit(df[[post_avg]])
    
    if (use_mean) {
      pre_val <- signif(mean(pre_avg_data), sigdig2)
      pre_sd <- signif(sd(pre_avg_data), sigdig2)
      post_val <- signif(mean(post_avg_data), sigdig2)
      post_sd <- signif(sd(post_avg_data), sigdig2)
    } else {
      pre_val <- signif(median(pre_avg_data), sigdig2)
      pre_sd <- paste0(signif(min(pre_avg_data), 1), " - ", signif(max(pre_avg_data), sigdig1))
      post_val <- signif(median(post_avg_data), sigdig2)
      post_sd <- paste0(signif(min(post_avg_data), 1), " - ", signif(max(post_avg_data), sigdig1))
    }
    
    ## Compute p-value for overall average
    if (pre_normality && post_normality) {
      test <- t.test(pre_avg_data, post_avg_data, paired = TRUE)
    } else {
      test <- wilcox.test(pre_avg_data, post_avg_data, paired = TRUE)
    }
    
    avg_row <- data.frame(
      Item = sectionTitle,
      Pre_Value = pre_val,
      Pre_SD_or_Range = pre_sd,
      Post_Value = post_val,
      Post_SD_or_Range = post_sd,
      P_Value = round(test$p.value, sigdig4)
    )
    
    ## Add to top of table
    table_df <- rbind(avg_row, table_df)
  }
  
  ## Create flextable
  library(flextable)
  ft <- flextable(table_df)
  
  ## set format for flextable
  ## Rename headers
  ft <- set_header_labels(ft, 
    Pre_Value = paste("Pre", value_label),
    Pre_SD_or_Range = paste("Pre", sd_range_label),
    Post_Value = paste("Post", value_label),
    Post_SD_or_Range = paste("Post", sd_range_label),
    P_Value = "p-value")
  
  ## Bold first row if average is included
  if (include_measure == 'Yes') {
    ft <- bold(ft, i = 1, bold = TRUE)
  }
  
  ## Bold all column headers
  ft <- bold(ft, part = "header")
  
  ## Right-align numeric columns
  ft <- align(ft, j = c("Pre_Value", "Pre_SD_or_Range", "Post_Value", "Post_SD_or_Range", "P_Value"), align = "right", part = "all")
  
  ## set format of flextables
  ft <- autofit(ft)
  ft <- height(ft, height= .1)
  ft <- width(ft, j=1, 2.70)
  ft <- width(ft, j=2, 0.8)
  ft <- width(ft, j=3, 0.9)
  ft <- width(ft, j=4, 0.9)
  ft <- width(ft, j=5, 0.9)
  ft <- width(ft, j=6, 0.9)
  
  ## Shade every other row starting from second
  row_indices <- seq(2, nrow(table_df), by = 2)
  ft <- bg(ft, i = row_indices, bg = "#EFEFEF")
  
  ## align cells at top
  ft <- valign(ft, i=NULL, j=NULL, part="all", valign="top")
  ft <- padding(ft, i=NULL, padding.top=.7, padding.bottom=.7)
  ft <- padding(ft, i = NULL, padding.top = 1, padding.bottom = 1)
  ft <- fontsize(ft, i = NULL, j = NULL, size = 10, part = "body")

  
  for (i in seq_len(nrow(table_df))) {
    if (table_df$P_Value[i] < 0.05) {
      bg_color <- if (i %% 2 == 0) upperselectorcolor else lowerselectorcolor  
      ft <- bg(ft, i = i, j = 6, bg = bg_color)
    }
  }

  ft <- valign(ft, i=NULL, j=NULL, valign="top", part="all")
  ft <- align(ft, j=2:6, align="right", part="all")
  ft <- vline(ft, j=1)
  ft <- vline(ft, j=3)
  ft <- vline(ft, j=5)
  
  ## Return flextable
  return(ft)
}
```

```{r build measure likert to handle a dynamic number of levels and a custom color palette}

## Define the function
create_likert_plot <- function(df, scale_var, scale_title = "Likert Scale Plot", item_label = NULL, debug = FALSE, palette_name = "PRGn", custom_colors = NULL) {
  
  ## default function call
  ## create_likert_plot(df=vetupcollege, scale_var="POST_PLC_IS_Avg_f", scale_title = "Instructor Support Dimension", item_label="Instructor Support", debug = TRUE)
  
  ## default function call2
  ## create_likert_plot(df = vetupcollege, scale_var = "POST_PLC_IS_Avg_f", scale_title = "Instructor Support Dimension", item_label = "Instructor provided timely feedback and support throughout the course.", palette_name = "RdYlGn")

  ## default function call3
  ## Or with custom hex colors
  ## create_likert_plot(df = vetupcollege, scale_var = "POST_PLC_IS_Avg_f", scale_title = "Instructor Support Dimension", item_label = "Instructor provided timely feedback and support throughout the course.",  custom_colors = c("#d73027", "#fc8d59", "#fee090", "#FFFFCC","#e0f3f8", "#91bfdb", "#4575b4"))
  
  ## Set default item label if not provided
  if (is.null(item_label)) item_label <- scale_var
  
  ## Wrap long label for display
  wrap_label <- function(label, width = 40) {
    paste(strwrap(label, width = width), collapse = "\n")
  }
  item_label_wrapped <- wrap_label(item_label)
  
  
  ## Select and rename the relevant column
  ## sym(scale_var) turns the string "POST_PLC_IS_Avg_f" into a symbol so dplyr can use it as a column name.
  ## !! unquotes the symbol so it can be evaluated
  ## := allows dynamic renaming of the column using the value of item_label
  ## when not in a function this is the same as:
  ## dplyr::select(Participant = ParticipantId, "Instructor Support" = POST_PLC_IS_Avg_f)
  likert_subset <- df %>%
    dplyr::select(Participant = ParticipantId, !!item_label_wrapped := !!sym(scale_var))

  ## Convert to long format
  likert_long <- likert_subset %>%
    pivot_longer(!Participant, names_to = "Item", values_to = "Response") 
  
  ## Group and count responses
  likert_long_group <- likert_long %>%
    group_by(Item, Response) %>%
    count() %>%
    filter(!is.na(Response)) %>%
    group_by(Item) %>%
    mutate(per = prop.table(n) * 100) %>%
    as.data.frame()
  
  ## Remove count column
  likert_long_group$n <- NULL
  
  ## Ensure all factor levels are present
  all_levels <- levels(df[[scale_var]])
  for (lvl in all_levels) {
    if (!lvl %in% likert_long_group$Response) {
      likert_long_group <- rbind(likert_long_group, data.frame(Item = item_label_wrapped, Response = lvl, per = 0))
    }
  }
  
  ## Pivot wider
  likert_wide <- likert_long_group %>%
    pivot_wider(names_from = Response, values_from = per, values_fn = sum)
  
  ## Reorder columns
  likert_wide <- likert_wide[, c("Item", all_levels)]
  
  ## Replace NAs with 0
  likert_wide[is.na(likert_wide)] <- 0
  
  ## Convert to dataframe
  likert_wide <- as.data.frame(likert_wide)
  
  ## Dynamically generate color palette
  num_levels <- length(all_levels)
  
  if (!is.null(custom_colors)) {
    likertPalette <- custom_colors
	} else {
		base_palette <- brewer.pal(min(num_levels, 11), palette_name)
    
	  if (num_levels %% 2 == 1) {
		## Odd number of levels: insert "#FFFFCC" as the center color rather than the default near white
		half <- floor(num_levels / 2)
		left_colors <- colorRampPalette(base_palette[1:half])(half)
		right_colors <- colorRampPalette(base_palette[(length(base_palette) - half + 1):length(base_palette)])(half)
		likertPalette <- c(left_colors, "#FFFFCC", right_colors)
	  } else {
		## Even number of levels: use full interpolated palette
		likertPalette <- colorRampPalette(base_palette)(num_levels)
	  }
  }

  ## Define origNames globally for use in panel function
  origNames <<- all_levels  ## <<- assigns to global environment for use in myPanelFunc
	
  ## Define dynamic panel function to add percentages
	 myPanelFunc <- function(...) {
	  ## Draw the base likert bars
	  panel.likert(...)
	  
	  ## Capture all arguments passed to the panel
	  vals <- list(...)
	  
	  ## Create a data frame with x (segment widths), y (row positions), and groups (factor levels)
	  DF <- data.frame(x = vals$x, y = vals$y, groups = vals$groups)
	  
	  ## Convert group labels to numeric positions based on origNames
	  grps <- as.character(DF$groups)
	  for (i in seq_along(origNames)) {
		grps <- sub(paste0("^", origNames[i]), i, grps)
	  }
	  
	  ## Order the data by row and group index
	  DF <- DF[order(DF$y, grps), ]
	  
	  ## Calculate label positions for each segment
	  DF$correctX <- ave(DF$x, DF$y, FUN = function(x) {
		## For negative segments (left side), reverse cumulative sum and center
		x[x < 0] <- rev(cumsum(rev(x[x < 0]))) - x[x < 0] / 2
		## For positive segments (right side), cumulative sum and center
		x[x > 0] <- cumsum(x[x > 0]) - x[x > 0] / 2
		return(x)
	  })
	  
	  ## Collapse adjacent segments with same label and row
	  subs <- sub(" Positive$", "", DF$groups)
	  collapse <- subs[-1] == subs[-length(subs)] & DF$y[-1] == DF$y[-length(DF$y)]
	  
	  ## Calculate absolute widths and adjust collapsed segments
	  DF$abs <- abs(DF$x)
	  DF$abs[c(collapse, FALSE)] <- DF$abs[c(collapse, FALSE)] + DF$abs[c(FALSE, collapse)]
	  DF$correctX[c(collapse, FALSE)] <- 0
	  DF <- DF[c(TRUE, !collapse), ]
	  
	  ## Calculate percentages from segment widths
	  DF$perc_num <- round(ave(DF$abs, DF$y, FUN = function(x) x / sum(x) * 100), 0)
	  
	  ## Filter out percentages < 10%
	  DF <- DF[DF$perc_num >= 10, ]
	  
	  ## Format labels
	  DF$perc <- paste0(DF$perc_num, "%")
	  
	  ## Draw percentage labels
	  panel.text(x = DF$correctX, y = DF$y, label = DF$perc, cex = 0.8)
	  
	  ## Optional debug output
	  if (exists("debug") && debug) {
		print(DF)
	  }
	}
	  
  
 ## Calculate dynamic xlim
  midpoint <- ceiling(num_levels / 2)
  left_levels <- all_levels[1:(midpoint - 1)]
  right_levels <- all_levels[midpoint:num_levels]
  
  max_neg <- max(rowSums(likert_wide[, left_levels, drop = FALSE]), na.rm = TRUE)
  max_pos <- max(rowSums(likert_wide[, right_levels, drop = FALSE]), na.rm = TRUE)
  
  buffer <- 5
  xlim_vals <- c(-max_neg - buffer, max_pos + buffer)

  ## Plot settings
  parSettings <- list(
    layout.widths = list(left.left.padding = 2),
    axis.line = list(col = "transparent")
  )
  
## Create the plot
  plot.likert(
    Item ~ ., 
    likert_wide, 
    xlab = NULL, 
    ylab = "", 
    main = list(scale_title, x = unit(0.30, "npc"), cex = 0.95), 
    adj = 0, 
    col = likertPalette, 
    xlim = xlim_vals, 
    scales = list(relation = "free", x = list(draw = FALSE)),
    auto.key = list(columns = 4, cex = 0.7, text = all_levels), 
    par.settings = parSettings,  
    rightAxis = FALSE,
    panel = myPanelFunc
  )
}
```

```{r build likert figure to handle multiple items with dynamic levels and optional custom color palette}

## Function definition
create_likert_plot_multi <- function(df, scale_vars,
  scale_title = "Likert Scale Plot", item_labels = NULL,
  debug = FALSE, palette_name = "PRGn", custom_colors = NULL) {
  
  ## default function call
  ## create_likert_plot_multi(df = vetupcollege, POST_ISI_Var, scale_title = "Instructor Support Items", POST_ISI_Labels, palette_name = "RdYlGn")
  
  ## Default function call
  ## create_likert_plot_multi(df = vetupcollege, scale_vars = c("POST_PLC_ISI_01_f", "POST_PLC_ISI_02_f", "POST_PLC_ISI_03_f"), scale_title = "Instructor Support Items", item_labels = c("Support Q1", "Support Q2", "Support Q3"), palette_name = "RdYlGn")
  
  ## Default call with custom hex colors
  ## create_likert_plot_multi(df = vetupcollege, scale_vars = c("POST_PLC_ISI_01_f", "POST_PLC_ISI_02_f", "POST_PLC_ISI_03_f"), scale_title = "Instructor Support Items", item_labels = POST_ISI_Labels, custom_colors = c("#d73027", "#fc8d59", "#fee090", "#FFFFCC", "#e0f3f8", "#91bfdb", "#4575b4"))
  
  ## Set default item labels if not provided
  if (is.null(item_labels)) item_labels <- scale_vars
  
  ## Wrap long labels for display
  wrap_label <- function(label, width = 40) {
    paste(strwrap(label, width = width), collapse = "\n")
  }
  item_labels <- sapply(item_labels, wrap_label)
  
  ## Select relevant columns without renaming
  likert_subset <- df %>%
    dplyr::select(Participant = ParticipantId, all_of(scale_vars))
  
  ## Convert to long format and apply item labels for display
  likert_long <- likert_subset %>%
    pivot_longer(!Participant, names_to = "Item", values_to = "Response") %>%
    mutate(Item = factor(Item, levels = scale_vars, labels = item_labels))
  
  ## Group and count responses
  likert_long_group <- likert_long %>%
    group_by(Item, Response) %>%
    count() %>%
    filter(!is.na(Response)) %>%
    group_by(Item) %>%
    mutate(per = prop.table(n) * 100) %>%
    as.data.frame()
  
  ## Remove count column
  likert_long_group$n <- NULL
  
  ## Ensure all factor levels are present for each item
  all_levels <- levels(df[[scale_vars[1]]])  ## assumes all items share the same levels
  for (item in unique(likert_long_group$Item)) {
    for (lvl in all_levels) {
      if (!any(likert_long_group$Item == item & likert_long_group$Response == lvl)) {
        likert_long_group <- rbind(likert_long_group, data.frame(Item = item, Response = lvl, per = 0))
      }
    }
  }
  
  ## Pivot to wider format
  likert_wide <- likert_long_group %>%
    pivot_wider(names_from = Response, values_from = per, values_fn = sum)
  
  ## Reorder columns
  likert_wide <- likert_wide[, c("Item", all_levels)]
  
  ## Replace NAs with 0
  likert_wide[is.na(likert_wide)] <- 0
  
  ## Convert to dataframe
  likert_wide <- as.data.frame(likert_wide)
  
  ## Dynamically generate color palette
  num_levels <- length(all_levels)
  
  if (!is.null(custom_colors)) {
    likertPalette <- custom_colors
  } else {
    if (!(palette_name %in% rownames(brewer.pal.info))) palette_name <- "PRGn"
    max_colors <- brewer.pal.info[palette_name, "maxcolors"]
    base_palette <- brewer.pal(min(num_levels, max_colors), palette_name)
    
    if (num_levels %% 2 == 1) {
      half <- floor(num_levels / 2)
      left_colors <- colorRampPalette(base_palette[1:half])(half)
      right_colors <- colorRampPalette(base_palette[(length(base_palette) - half + 1):length(base_palette)])(half)
      likertPalette <- c(left_colors, "#FFFFCC", right_colors)
    } else {
      likertPalette <- colorRampPalette(base_palette)(num_levels)
    }
  }

  ## Define origNames globally for use in panel function
  origNames <<- all_levels  ## <<- assigns to global environment for use in myPanelFunc
  
  ## Define dynamic panel function to add percentages
  myPanelFunc <- function(...) {
    
	## Draw the base likert bars
	panel.likert(...)
	
	## Capture all arguments passed to the panel
    vals <- list(...)

	## Create a data frame with x (segment widths), y (row positions), and groups (factor levels)
    DF <- data.frame(x = vals$x, y = vals$y, groups = vals$groups)
	
	## Convert group labels to numeric positions based on origNames
    grps <- as.character(DF$groups)
    for (i in seq_along(origNames)) {
      grps <- sub(paste0("^", origNames[i]), i, grps)
    }
	
	## Order the data by row and group index
    DF <- DF[order(DF$y, grps), ]
	
	## Calculate label positions for each segment
    DF$correctX <- ave(DF$x, DF$y, FUN = function(x) {
      
	  ## For negative segments (left side), reverse cumulative sum and center
	  x[x < 0] <- rev(cumsum(rev(x[x < 0]))) - x[x < 0] / 2
	  
	  ## For positive segments (right side), cumulative sum and center
      x[x > 0] <- cumsum(x[x > 0]) - x[x > 0] / 2
      return(x)
    })
	
	## Collapse adjacent segments with same label and row
    subs <- sub(" Positive$", "", DF$groups)
    collapse <- subs[-1] == subs[-length(subs)] & DF$y[-1] == DF$y[-length(DF$y)]
	
	## Calculate absolute widths and adjust collapsed segments
    DF$abs <- abs(DF$x)
    DF$abs[c(collapse, FALSE)] <- DF$abs[c(collapse, FALSE)] + DF$abs[c(FALSE, collapse)]
    DF$correctX[c(collapse, FALSE)] <- 0
    DF <- DF[c(TRUE, !collapse), ]
	
	## Calculate percentages from segment widths
    DF$perc_num <- round(ave(DF$abs, DF$y, FUN = function(x) x / sum(x) * 100), 0)
	
	## Filter out percentages < 10%
    DF <- DF[DF$perc_num >= 10, ]
	
	## Format labels
	DF$perc <- paste0(DF$perc_num, "%")
	
	## Draw percentage labels
    panel.text(x = DF$correctX, y = DF$y, label = DF$perc, cex = 0.8)
   
	## Optional debug output
	if (exists("debug") && debug) {
	print(DF)
	}
  }
  
  ## Calculate dynamic xlim
  midpoint <- ceiling(num_levels / 2)
  left_levels <- all_levels[1:(midpoint - 1)]
  right_levels <- all_levels[midpoint:num_levels]
  
  max_neg <- max(rowSums(likert_wide[, left_levels, drop = FALSE]), na.rm = TRUE)
  max_pos <- max(rowSums(likert_wide[, right_levels, drop = FALSE]), na.rm = TRUE)
  
  ## Add buffer to ensure space for labels
  buffer <- 5
  xlim_vals <- c(-max_neg - buffer, max_pos + buffer)
  
  ## Plot settings
  parSettings <- list(
    layout.widths = list(left.left.padding = 2),
    axis.line = list(col = "transparent")
  )
  
  ## Create the plot
  plot.likert(
    Item ~ ., 
    likert_wide, 
    xlab = NULL, 
    ylab = "", 
    main = list(scale_title, x = unit(0.30, "npc"), cex = 0.95), 
    adj = 0, 
    col = likertPalette, 
    xlim = xlim_vals, 
    scales = list(relation = "free", x = list(draw = FALSE)),
    auto.key = list(columns = 4, cex = 0.7, text = all_levels), 
    par.settings = parSettings,  
    rightAxis = FALSE,
    panel = myPanelFunc
  )
}
```

```{r build dumbbell figure}
## Function definition
create_dumbbell_chart <- function(
  df,
  pre_vars,
  post_vars,
  item_labels,
  pre_normality,
  post_normality,
  factor_vars = NULL,
  figure_title = "Dumbbell Chart",
  color_scheme = c("#1f77b4", "#ff7f0e"),
  PrePost = TRUE,
  debug = FALSE,
  order_by_change = FALSE ## toggle to sort data by change
) {
  
  ## default function call
  ## Use one of the original factor variables to get Likert levels
  ## create_dumbbell_chart(df = vetupcollege, pre_vars = c("PRE_BELONG_Avg", "PRE_SUPPORT_Avg", "PRE_CONFIDENCE_Avg"), post_vars = c("POST_BELONG_Avg", "POST_SUPPORT_Avg", "POST_CONFIDENCE_Avg"),   item_labels = c("Sense of Belonging", "Instructor Support", "Confidence in STEM"), pre_normality = c(FALSE, TRUE, TRUE), post_normality = c(TRUE, TRUE, TRUE), factor_vars = c("PRE_BELONG"), figure_title = "Vet Up! College Gains", PrePost = TRUE)

  ## Determine whether to use mean or median based on majority normality. Use the mean if more than half of the items are normally distributed in both pre and post.
  combined_normality <- mapply(function(pre, post) pre & post, pre_normality, post_normality)
  use_mean <- sum(combined_normality) > (length(combined_normality) / 2)

  if (debug) {
	cat("Using", ifelse(use_mean, "mean", "median"), "for all items based on majority normality.\n")
	 }

  ## Compute summary statistics
  ## Explicitly set Pre and Post values to null values  of numeric (real/double) type
  summary_df <- data.frame(
    label = item_labels,
    Pre = NA_real_,
    Post = NA_real_,
    stringsAsFactors = FALSE
  )

  for (i in seq_along(pre_vars)) {
    if (use_mean) {
      summary_df$Pre[i] <- mean(df[[pre_vars[i]]], na.rm = TRUE)
      summary_df$Post[i] <- mean(df[[post_vars[i]]], na.rm = TRUE)
    } else {
      summary_df$Pre[i] <- median(df[[pre_vars[i]]], na.rm = TRUE)
      summary_df$Post[i] <- median(df[[post_vars[i]]], na.rm = TRUE)
    }
  }

  ## Calculate change magnitude
  summary_df <- summary_df %>%
    mutate(Change = abs(Post - Pre))

  ## Optional sorting by change
  if (order_by_change) {
    summary_df <- summary_df %>% arrange(desc(Change))
  }

  if (debug) {
    print(summary_df)
  }

  ## Reshape using pivot_longer
  summary_long <- summary_df %>%
    dplyr::select(label, Pre, Post) %>%
    pivot_longer(cols = c(Pre, Post), names_to = "Time", values_to = "Value")

  ## Set factor levels to preserve sorted order
  summary_long$label <- factor(summary_long$label, levels = rev(summary_df$label))

  ## Rename time labels
  if (PrePost) {
    summary_long$Time <- factor(summary_long$Time, levels = c("Pre", "Post"), labels = c("Pre", "Post"))
  } else {
    summary_long$Time <- factor(summary_long$Time, levels = c("Pre", "Post"), labels = c("Before", "Now"))
  }

  ## Determine Likert scale labels from factor_vars
  if (!is.null(factor_vars)) {
    factor_levels <- levels(df[[factor_vars[1]]])
    x_breaks <- seq_along(factor_levels)
    x_labels <- paste0(x_breaks, "\n", factor_levels)
    x_limits <- c(min(x_breaks), max(x_breaks))
	
	if (debug) {
      cat("Factor levels used for x-axis:\n")
      print(factor_levels)
    }	
  } else {
    ## Default to 1–4 Likert scale
    x_breaks <- 1:4
    x_labels <- c("1\nNot at all", "2\nSomewhat", "3\nA fair amount", "4\nA great deal")
    x_limits <- c(1, 4)
  }

  if (debug) {
    print(summary_long)
  }
  
  ## get time labels from call to use in ggplot
	if (PrePost) {
	  time_labels <- c("Pre", "Post")
	} else {
	  time_labels <- c("Before", "Now")
	}
  
  ## identify topmost item to display the labels for ggplot
	top_label <- summary_df$label[1]
	top_pre <- summary_df$Pre[1]
	top_post <- summary_df$Post[1]

  ## Create dumbbell chart
  dbplot <- ggplot(summary_long, aes(x = Value, y = label)) +
    geom_line(aes(group = label), color = "gray70") +
    geom_point(aes(color = Time), size = 8) +
    geom_text(aes(label = sprintf("%.1f", Value)),       color = "white", size = 3.2, fontface = "bold",       vjust = 0.5, hjust = 0.5) +
    annotate("text", x = top_pre, y = top_label, label = time_labels[1], vjust = -2, fontface = "bold", color=color_scheme[1]) +
    annotate("text", x = top_post, y = top_label, label = time_labels[2], vjust = -2, fontface = "bold", color=color_scheme[2]) +
    scale_color_manual(values = color_scheme, name = NULL) +
    scale_x_continuous(
      breaks = x_breaks,
      labels = x_labels,
      limits = x_limits
    ) +
    labs(title = figure_title, x = NULL, y = NULL) +
    theme_classic() +
    theme(
      legend.position = "none",
      axis.line.x = element_blank(),
      axis.line.y = element_blank(),
	  axis.ticks.x = element_blank(),
      axis.ticks.y = element_blank(),
	  axis.text.x = element_blank()
    )

  return(dbplot)
}
```

```{r build dumbbell no y-axis labels figure}
## Function definition
create_dumbbell_no_y_chart <- function(
  df,
  pre_vars,
  post_vars,
  item_labels,
  pre_normality,
  post_normality,
  factor_vars = NULL,
  figure_title = "Dumbbell Chart",
  color_scheme = c("#1f77b4", "#ff7f0e"),
  PrePost = TRUE,
  debug = FALSE,
  order_by_change = FALSE ## toggle to sort data by change
) {
  
  ## default function call
  ## Use one of the original factor variables to get Likert levels
  ## create_dumbbell_no_y_chart(df = vetupcollege, pre_vars = c("PRE_BELONG_Avg", "PRE_SUPPORT_Avg", "PRE_CONFIDENCE_Avg"), post_vars = c("POST_BELONG_Avg", "POST_SUPPORT_Avg", "POST_CONFIDENCE_Avg"),   item_labels = c("Sense of Belonging", "Instructor Support", "Confidence in STEM"), pre_normality = c(FALSE, TRUE, TRUE), post_normality = c(TRUE, TRUE, TRUE), factor_vars = c("PRE_BELONG"), figure_title = "Vet Up! College Gains", PrePost = TRUE)

  ## default function call2
  ## create_dumbbell_no_y_chart(df = vetupcollege, pre_vars = c("PRE_BELONG_Avg"), post_vars = c("POST_BELONG_Avg"),   item_labels = c("Sense of Belonging"), pre_normality = c(FALSE), post_normality = c(FALSE), factor_vars = c("PRE_BELONG_LKRT"), figure_title = "Vet Up! College Belonging Gains", PrePost = TRUE, debug=TRUE)

  ## Determine whether to use mean or median based on majority normality. 
  combined_normality <- mapply(function(pre, post) pre & post, pre_normality, post_normality)
  use_mean <- sum(combined_normality) > (length(combined_normality) / 2)

  if (debug) {
	cat("Using", ifelse(use_mean, "mean", "median"), "for all items based on majority normality.\n")
	 }

  ## Compute summary statistics
  ## Explicitly set Pre and Post values to null values  of numeric (real/double) type
  summary_df <- data.frame(
    label = item_labels,
    Pre = NA_real_,
    Post = NA_real_,
    stringsAsFactors = FALSE
  )

  for (i in seq_along(pre_vars)) {
    if (use_mean) {
      summary_df$Pre[i] <- mean(df[[pre_vars[i]]], na.rm = TRUE)
      summary_df$Post[i] <- mean(df[[post_vars[i]]], na.rm = TRUE)
    } else {
      summary_df$Pre[i] <- median(df[[pre_vars[i]]], na.rm = TRUE)
      summary_df$Post[i] <- median(df[[post_vars[i]]], na.rm = TRUE)
    }
  }

  ## Calculate change magnitude
  summary_df <- summary_df %>%
    mutate(Change = abs(Post - Pre))

  ## Optional sorting by change
  if (order_by_change) {
    summary_df <- summary_df %>% arrange(desc(Change))
  }

  if (debug) {
    print(summary_df)
  }

  ## Reshape using pivot_longer
  summary_long <- summary_df %>%
    dplyr::select(label, Pre, Post) %>%
    pivot_longer(cols = c(Pre, Post), names_to = "Time", values_to = "Value")

  ## Set factor levels to preserve sorted order
  summary_long$label <- factor(summary_long$label, levels = rev(summary_df$label))

  ## Rename time labels
  if (PrePost) {
    summary_long$Time <- factor(summary_long$Time, levels = c("Pre", "Post"), labels = c("Pre", "Post"))
  } else {
    summary_long$Time <- factor(summary_long$Time, levels = c("Pre", "Post"), labels = c("Before", "Now"))
  }

  ## Determine Likert scale labels from factor_vars
  if (!is.null(factor_vars)) {
    factor_levels <- levels(df[[factor_vars[1]]])
    x_breaks <- seq_along(factor_levels)
    x_labels <- paste0(x_breaks, "\n", factor_levels)
    x_limits <- c(min(x_breaks), max(x_breaks))
	
	if (debug) {
      cat("Factor levels used for x-axis:\n")
      print(factor_levels)
    }	
  } else {
    ## Default to 1–4 Likert scale
    x_breaks <- 1:4
    x_labels <- c("1\nNot at all", "2\nSomewhat", "3\nA fair amount", "4\nA great deal")
    x_limits <- c(1, 4)
  }

  if (debug) {
    print(summary_long)
  }
  
  ## get time labels from call to use in ggplot
	if (PrePost) {
	  time_labels <- c("Pre", "Post")
	} else {
	  time_labels <- c("Before", "Now")
	}
  
  ## identify topmost item to display the labels for ggplot
	top_label <- summary_df$label[1]
	top_pre <- summary_df$Pre[1]
	top_post <- summary_df$Post[1]

  ## Create dumbbell chart
  dbplot <- ggplot(summary_long, aes(x = Value, y = label)) +
    geom_line(aes(group = label), color = "gray70") +
    geom_point(aes(color = Time), size = 8) +
    geom_text(aes(label = sprintf("%.1f", Value)),       color = "white", size = 3.2, fontface = "bold",       vjust = 0.5, hjust = 0.5) +
    annotate("text", x = top_pre, y = top_label, label = time_labels[1], vjust = -2, fontface = "bold", color=color_scheme[1]) +
    annotate("text", x = top_post, y = top_label, label = time_labels[2], vjust = -2, fontface = "bold", color=color_scheme[2]) +
    scale_color_manual(values = color_scheme, name = NULL) +
    scale_x_continuous(
      breaks = x_breaks,
      labels = x_labels,
      limits = x_limits
    ) +
    labs(title = figure_title, x = NULL, y = NULL) +
    theme_classic() +
    theme(
      legend.position = "none",
      axis.line.x = element_blank(),
      axis.line.y = element_blank(),
	  axis.ticks.x = element_blank(),
      axis.ticks.y = element_blank(),
	  axis.text.x = element_blank(),
	  axis.text.y = element_blank(),
	  plot.title = element_text(hjust = .5)  
    )

  return(dbplot)
}
```

```{r create numeric variables}
## Create leadership numeric variables
SampleMathMergeDF <- SampleMathMergeDF %>%
  mutate(PRE_OFFICIAL_SRVY_n = as.numeric(PRE_OFFICIAL_SRVY))
  
SampleMathMergeDF <- SampleMathMergeDF %>% mutate( PRE_STUDENTID_n = as.numeric(PRE_STUDENTID))

SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_CA_01_n = as.numeric(PRE_CA_01))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_CA_02_n = as.numeric(PRE_CA_02))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_CA_03_n = as.numeric(PRE_CA_03))

SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_SE_01_n = as.numeric(PRE_SE_01))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_SE_02_n = as.numeric(PRE_SE_02)) 
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_SE_03_n = as.numeric(PRE_SE_03))

SampleMathMergeDF <- SampleMathMergeDF %>% mutate( POST_STUDENTID_n = as.numeric(POST_STUDENTID))
 
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_SRVY_POST_HS_GRAD_n = as.numeric(POST_SRVY_POST_HS_GRAD))

SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_CA_01_n = as.numeric(POST_CA_01))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_CA_02_n = as.numeric(POST_CA_02))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_CA_03_n = as.numeric(POST_CA_03))

SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_SE_01_n = as.numeric(POST_SE_01))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_SE_02_n = as.numeric(POST_SE_02)) 
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_SE_03_n = as.numeric(POST_SE_03))

SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_PRGM_FDBCK_02_01_n = as.numeric(POST_PRGM_FDBCK_02_01))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_PRGM_FDBCK_02_02_n = as.numeric(POST_PRGM_FDBCK_02_02))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_PRGM_FDBCK_02_03_n = as.numeric(POST_PRGM_FDBCK_02_03))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_PRGM_FDBCK_02_04_n = as.numeric(POST_PRGM_FDBCK_02_04))

SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_STPND_MTVTNG_FCTR_n = as.numeric(POST_STPND_MTVTNG_FCTR))
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_RCMD_PRGM_n = POST_RCMD_PRGM))
```

```{r create factor variables}
## create factor variables and set levels
SampleMathMergeDF$PRE_OFFICIAL_SRVY_f <- factor(SampleMathMergeDF$PRE_OFFICIAL_SRVY_n, levels = c(0,1), labels = c("no", "yes"))
  
SampleMathMergeDF$PRE_CA_01_f <- factor(SampleMathMergeDF$PRE_CA_01_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))
SampleMathMergeDF$PRE_CA_02_f <- factor(SampleMathMergeDF$PRE_CA_02_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))
SampleMathMergeDF$PRE_CA_03_f <- factor(SampleMathMergeDF$PRE_CA_03_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))

SampleMathMergeDF$PRE_SE_01_f <- factor(SampleMathMergeDF$PRE_SE_01_n, levels = c(1, 2, 3, 4, 5), labels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident"))
SampleMathMergeDF$PRE_SE_02_f <- factor(SampleMathMergeDF$PRE_SE_02_n, levels = c(1, 2, 3, 4, 5), labels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident"))
SampleMathMergeDF$PRE_SE_03_f <- factor(SampleMathMergeDF$PRE_SE_03_n, levels = c(1, 2, 3, 4, 5), labels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident"))

SampleMathMergeDF$POST_SRVY_POST_HS_GRAD_f <- SampleMathMergeDF$POST_SRVY_POST_HS_GRAD_n, levels = c(0, 1, 2, 3, 4), labels = c("I chose not to answer", "starting directly in the workforce", "attending community college to complete a certification or associates degree", "attending community college and transferring to a university", "attending a 4-year college or university"))

SampleMathMergeDF$POST_CA_01_f <- factor(SampleMathMergeDF$POST_CA_01_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))
SampleMathMergeDF$POST_CA_02_f <- factor(SampleMathMergeDF$POST_CA_02_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))
SampleMathMergeDF$POST_CA_03_f <- factor(SampleMathMergeDF$POST_CA_03_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))

SampleMathMergeDF$POST_SE_01_f <- factor(SampleMathMergeDF$POST_SE_01_n, levels = c(1, 2, 3, 4, 5), labels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident"))
SampleMathMergeDF$POST_SE_02_f <- factor(SampleMathMergeDF$POST_SE_02_n, levels = c(1, 2, 3, 4, 5), labels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident"))
SampleMathMergeDF$POST_SE_03_f <- factor(SampleMathMergeDF$POST_SE_03_n, levels = c(1, 2, 3, 4, 5), labels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident"))

SampleMathMergeDF$POST_PRGM_FDBCK_02_01_f <- factor(SampleMathMergeDF$POST_PRGM_FDBCK_02_01_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))
SampleMathMergeDF$POST_PRGM_FDBCK_02_02_f <- factor(SampleMathMergeDF$POST_PRGM_FDBCK_02_02_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))
SampleMathMergeDF$POST_PRGM_FDBCK_02_03_f <- factor(SampleMathMergeDF$POST_PRGM_FDBCK_02_03_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))
SampleMathMergeDF$POST_PRGM_FDBCK_02_04_f <- factor(SampleMathMergeDF$POST_PRGM_FDBCK_02_04_n, levels = c(1, 2, 3, 4, 5), labels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree"))

SampleMathMergeDF$POST_STPND_MTVTNG_FCTR_f <- factor(SampleMathMergeDF$POST_STPND_MTVTNG_FCTR_n, levels = c(0,1), labels = c("no", "yes")) 
SampleMathMergeDF$POST_RCMD_PRGM_f <- factor(SampleMathMergeDF$POST_RCMD_PRGM_n, levels = c(0,1), labels = c("no", "yes")) 
```

```{r create PRE_CA scales}
## 1 create PRE_CA scale
PRE_CA_Measure_LIST <- c('PRE_CA_01_n','PRE_CA_02_n','PRE_CA_03_n')

## 2 create PRE_CA list of measure definition items
PRE_CA_Measure_Definitions <- 
c("I'm aware of what studying math may be like.", "I'm aware of  the various math oriented career opportunities available.", "I'm aware of of math  career options I could specialize in.")

## 3 set whether the PRE_CA scale is a true measure or false a set of items
PRE_CA_Measuretf = True

## 4 set the PRE_CA measure average for true measures and round to 2 significant digits
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_CA_Measure_Avg = rowMeans(SampleMathMergeDF[PRE_CA_Measure_LIST], na.rm = TRUE))

SampleMathMergeDF$PRE_CA_Measure_Avg <- round(SampleMathMergeDF$PRE_CA_Measure_Avg, sigdig2)

## 5 Compute the PRE_CA cronbach alpha for a true measure
PRE_CA_Measure_alphasummary <- alpha(SampleMathMergeDF[PRE_CA_Measure_LIST], na.rm = TRUE)

PRE_CA_MeasureCA <- round(PRE_CA_Measure_alphasummary$total[1,1], sigdig2)

## 6 convert continuous PRE_CA_Measure_Avg into a likert value
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_CA_Measure_LKRT = case_when(
	PRE_CA_Measure_Avg <= 1.5 ~ "strongly disagree",
	PRE_CA_Measure_Avg <= 2.5 ~ "disagree",
	PRE_CA_Measure_Avg <= 3.5 ~ "neither agree nor disagree",
	PRE_CA_Measure_Avg <= 4.5 ~ "agree",
	PRE_CA_Measure_Avg <= 5 ~ "strongly agree"
	),
	## convert to a factor with all level explicitly defined
	PRE_CA_Measure_LKRT = factor(
	  PRE_CA_Measure_LKRT, levels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree")
    )
  )
	
## 7 check normality for the PRE_CA measure	
PRE_CA_Measure_normality <- check_measure_normality(SampleMathMergeDF, PRE_CA_Measure_LIST)
```

```{r create PRE_SE scales}
## 1 create PRE_SE scale
PRE_SE_Measure_LIST <- c('PRE_SE_01_n','PRE_SE_02_n','PRE_SE_03_n')

## 2 create PRE_SE list of measure definition items
PRE_SE_Measure_Definitions <- 
c("Complete the program activities for this summer program.", "Complete the first year of a math related major or job readiness program.", "Successfully complete all required courses in a math related major or job readiness program.")

## 3 set whether the PRE_SE scale is a true measure or false a set of items
PRE_SE_Measuretf = True

## 4 set the PRE_SE measure average for true measures and round to 2 significant digits
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_SE_Measure_Avg = rowMeans(SampleMathMergeDF[PRE_SE_Measure_LIST], na.rm = TRUE))

SampleMathMergeDF$PRE_SE_Measure_Avg <- round(SampleMathMergeDF$PRE_SE_Measure_Avg, sigdig2)

## 5 Compute the PRE_SE cronbach alpha for a true measure
PRE_SE_Measure_alphasummary <- alpha(SampleMathMergeDF[PRE_SE_Measure_LIST], na.rm = TRUE)

PRE_SE_MeasureCA <- round(PRE_SE_Measure_alphasummary$total[1,1], sigdig2)

## 6 convert continuous PRE_SE_Measure_Avg into a likert value
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(PRE_SE_Measure_LKRT = case_when(
	PRE_SE_Measure_Avg <= 1.5 ~ "not at all confident",
	PRE_SE_Measure_Avg <= 2.5 ~ "low confidence",
	PRE_SE_Measure_Avg <= 3.5 ~ "slightly confident",
	PRE_SE_Measure_Avg <= 4.5 ~ "moderately confident",
	PRE_SE_Measure_Avg <= 5   ~ "very confident"
	),
	## convert to a factor with all level explicitly defined
	PRE_SE_Measure_LKRT = factor(
	  PRE_SE_Measure_LKRT, levels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident")
    )
  )
	
## 7 check normality for the PRE_SE measure	
PRE_SE_Measure_normality <- check_measure_normality(SampleMathMergeDF, PRE_SE_Measure_LIST)
```

```{r create POST_CA scales}
## 1 create POST_CA scale
POST_CA_Measure_LIST <- c('POST_CA_01_n','POST_CA_02_n','POST_CA_03_n')

## 2 create POST_CA list of measure definition items
POST_CA_Measure_Definitions <- 
c("I'm aware of what studying math may be like.", "I'm aware of  the various math oriented career opportunities available.", "I'm aware of of math  career options I could specialize in.")

## 3 set whether the POST_CA scale is a true measure or false a set of items
POST_CA_Measuretf = True

## 4 set the POST_CA measure average for true measures and round to 2 significant digits
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_CA_Measure_Avg = rowMeans(SampleMathMergeDF[POST_CA_Measure_LIST], na.rm = TRUE))

SampleMathMergeDF$POST_CA_Measure_Avg <- round(SampleMathMergeDF$POST_CA_Measure_Avg, sigdig2)

## 5 Compute the POST_CA cronbach alpha for a true measure
POST_CA_Measure_alphasummary <- alpha(SampleMathMergeDF[POST_CA_Measure_LIST], na.rm = TRUE)

POST_CA_MeasureCA <- round(POST_CA_Measure_alphasummary$total[1,1], sigdig2)

## 6 convert continuous POST_CA_Measure_Avg into a likert value
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_CA_Measure_LKRT = case_when(
	POST_CA_Measure_Avg <= 1.5 ~ "strongly disagree",
	POST_CA_Measure_Avg <= 2.5 ~ "disagree",
	POST_CA_Measure_Avg <= 3.5 ~ "neither agree nor disagree",
	POST_CA_Measure_Avg <= 4.5 ~ "agree",
	POST_CA_Measure_Avg <= 5 ~ "strongly agree"
	),
	## convert to a factor with all level explicitly defined
	POST_CA_Measure_LKRT = factor(
	  POST_CA_Measure_LKRT, levels = c("strongly disagree", "disagree", "neither agree nor disagree", "agree", "strongly agree")
    )
  )
	
## 7 check normality for the POST_CA measure	
POST_CA_Measure_normality <- check_measure_normality(SampleMathMergeDF, POST_CA_Measure_LIST)
```

```{r create POST_SE scales}
## 1 create POST_SE scale
POST_SE_Measure_LIST <- c('POST_SE_01_n','POST_SE_02_n','POST_SE_03_n')

## 2 create POST_SE list of measure definition items
POST_SE_Measure_Definitions <- 
c("Complete the program activities for this summer program.", "Complete the first year of a math related major or job readiness program.", "Successfully complete all required courses in a math related major or job readiness program.")

## 3 set whether the POST_SE scale is a true measure or false a set of items
POST_SE_Measuretf = True

## 4 set the POST_SE measure average for true measures and round to 2 significant digits
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_SE_Measure_Avg = rowMeans(SampleMathMergeDF[POST_SE_Measure_LIST], na.rm = TRUE))

SampleMathMergeDF$POST_SE_Measure_Avg <- round(SampleMathMergeDF$POST_SE_Measure_Avg, sigdig2)

## 5 Compute the POST_SE cronbach alpha for a true measure
POST_SE_Measure_alphasummary <- alpha(SampleMathMergeDF[POST_SE_Measure_LIST], na.rm = TRUE)

POST_SE_MeasureCA <- round(POST_SE_Measure_alphasummary$total[1,1], sigdig2)

## 6 convert continuous POST_SE_Measure_Avg into a likert value
SampleMathMergeDF <- SampleMathMergeDF %>% mutate(POST_SE_Measure_LKRT = case_when(
	POST_SE_Measure_Avg <= 1.5 ~ "not at all confident",
	POST_SE_Measure_Avg <= 2.5 ~ "low confidence",
	POST_SE_Measure_Avg <= 3.5 ~ "slightly confident",
	POST_SE_Measure_Avg <= 4.5 ~ "moderately confident",
	POST_SE_Measure_Avg <= 5   ~ "very confident"
	),
	## convert to a factor with all level explicitly defined
	POST_SE_Measure_LKRT = factor(
	  POST_SE_Measure_LKRT, levels = c("not at all confident", "low confidence", "slightly confident", "moderately confident", "very confident")
    )
  )
	
## 7 check normality for the POST_SE measure	
POST_SE_Measure_normality <- check_measure_normality(SampleMathMergeDF, POST_SE_Measure_LIST)
```

```{r create POST_PRGM_FDBCK scales}
## 1 create POST_PRGM_FDBCK scale
POST_PRGM_FDBCK_Measure_LIST <- c('POST_PRGM_FDBCK_01_n','POST_PRGM_FDBCK_02_n','POST_PRGM_FDBCK_03_n', 'POST_PRGM_FDBCK_04_n')

## 2 create POST_PRGM_FDBCK list of measure definition items
POST_PRGM_FDBCK_Measure_Definitions <- 
c("This program has helped me consider whether the math field would be a good career fit for me.", "I learned about specific challenges in the math field.", "Participating in this program was a good use of my time.", "I felt supported by program faculty, staff, and other program participants.")

## 3 set whether the POST_PRGM_FDBCK scale is a true measure or false a set of items
POST_PRGM_FDBCK_Measuretf = False

## 7 check normality for the POST_PRGM_FDBCK measure	
POST_PRGM_FDBCK_Measure_normality <- check_measure_normality(SampleMathMergeDF, POST_PRGM_FDBCK_Measure_LIST)
```



## Executive Summary

### Key Findings

### Key Recommendations

## Introduction

### Program Objectives

## Evaluation Approach

### Evaluation Questions

## Evaluation Methods

### Description of Instruments

```{r Table Summary of constructs}

## Create Table Summary of Constructs, define columns
summaryOfConstructs <- data.frame('Evaluation Question', 'Measure', 'Item Description', 'Normality of Measure', 'Reliability of Measure', 'Source')



```

## Evaluation Findings

### Demographics

### Evaluation Question 1







